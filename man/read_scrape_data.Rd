% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_scrape_data.R
\name{read_scrape_data}
\alias{read_scrape_data}
\title{Read data extracted by webscraper}
\usage{
read_scrape_data(
  all_dates = FALSE,
  window = 31,
  window_pop = 31,
  coalesce_func = sum_na_rm,
  drop_noncovid_obs = TRUE,
  debug = FALSE,
  state = NULL,
  wide_data = TRUE
)
}
\arguments{
\item{all_dates}{logical, get all data from all dates recorded by webscraper}

\item{window}{int, how far to go back (in days) to look for values from a given
facility to populate NAs for ALL scraped variables. Used when all_dates is FALSE}

\item{window_pop}{int, how far to go back (in days) to look for values from a given
facility to populate NAs in Residents.Population. Used when coalesce_pop is TRUE}

\item{coalesce_func}{function, how to combine redundant rows}

\item{drop_noncovid_obs}{logical, drop rows missing all COVID variables}

\item{debug}{logical, print debug statements on number of rows maintained in}

\item{state}{character vector, states to limit data to}

\item{wide_data}{logical, return wide data as opposed to long}
}
\value{
dataframe with scraped data
}
\description{
Reads either time series or latest data from the web scraper runs.
}
\examples{
\dontrun{
read_scrape_data(all_dates = FALSE)
}
read_scrape_data(all_dates = TRUE, state = "Wyoming")

}
